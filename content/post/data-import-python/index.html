---
title: An Overview Of Importing Data In Python
author: Jun Ye
date: '2020-02-18'
slug: an-overview-of-importing-data-in-python
categories:
  - Post
tags:
  - Data Import
  - CSV
  - Python
  - Pandas
subtitle: "Understand which method should be used"
summary: ''
authors: 
- admin
lastmod: '2020-02-18T12:13:11+10:00'
featured: yes
image:
  caption: ''
  focal_point: ''
  placement: 2
  preview_only: false
projects: []
---



<p>The prerequisite for doing any data-related operations in Python, such as data cleansing, data aggregation, data transformation, and data visualisation, is to load data into Python. Depends on the types of data files (e.g. <code>.csv</code>, <code>.txt</code>, <code>.tsv</code>, <code>.html</code>, <code>.json</code>, Excel spreadsheets, relational databases etc.) and their size, different methods should be applied to deal with this initial operation accordingly. In this post, I will list some common methods for importing data in Python.</p>
<p>As usual, all required data and notebook can be accessed from <a href="https://github.com/Perishleaf/data-visualisation-scripts/tree/master/data_import_python">my Github</a>.</p>
<hr />
<div id="python-build-in-functions-read-readline-and-readlines" class="section level4">
<h4>1. Python build-in functions (<code>read()</code>, <code>readline()</code>, and <code>readlines()</code>)</h4>
<p>In general, a text file (<code>.txt</code>) is the most common file we will deal with. Text files are structured as a sequence of lines, where each line includes a sequence of characters. Let’s assume we need to import in Python the following text file (<code>sample.txt</code>).</p>
<pre class="bash"><code>Country/Region
Mainland China
Japan
Singapore
Hong Kong
Japan
Thailand
South Korea
Malaysia
Taiwan
Germany
Vietnam
France
Macau
UK
United Arab Emirates
US
Australia</code></pre>
<p>To import its content to Python, we need to first open it. This step is just like double-clicking a file to open it in our computer system. However, in Python, this is done by calling the <code>open()</code> built-in function. <code>open()</code> has a required argument that is the path to the file and an optional argument to indicate the mode (i.e. default argument ‘r’: open for reading; ‘w’: open for writing). With those set, <code>open()</code> then returns us a file object.</p>
<p>There are three methods to read content (i.e. <code>read()</code>, <code>readline()</code>, and <code>readlines()</code>) that can be called on this file object either by one or in combination.</p>
<ul>
<li><code>read(size=-1)</code>: this reads from the file based on the number of <code>size</code> bytes. If no argument is passed or <code>None</code> or <code>-1</code> is passed, then the entire file is read. <img src="Figure1.png" alt="Figure 1" /></li>
<li><p><code>readline(size=-1)</code>: this reads the entire line if no arguments are passed or <code>None</code> or <code>-1</code> is passed (Figure 2 upper panel). Or if passed with <code>siz</code>e, this reads the <code>size</code> number of characters from the line. Moreover, multiple <code>readline()</code> functions (Figure 2 lower panel) can be called sequentially, in which the next <code>readline()</code> function will continue from the end position of last <code>readline()</code> function. Note that output of the third <code>readline()</code> appends an extra newline character(<code>\n</code>, displayed as a new line). This can be avoided by using <code>print(reader.readline(5), end=’’)</code>. <img src="Figure2.png" alt="Figure 2" /></p></li>
<li><p><code>readlines()</code>: this reads all the lines or remaining lines from the file object and returns them as a list (Figure 3). <img src="Figure3.png" alt="Figure 3" /></p></li>
</ul>
<p>You might notice that all the above codes have <code>with</code> statements. The <code>with</code> statement provides a way for ensuring that the file is always closed after open. Without the <code>wit</code>h statement, we need explicitly to call <code>close()</code> for the file object. For instance:</p>
<pre class="python"><code>file = open(&quot;sample.txt&quot;)
data = file.read()
print(data)
file.close()</code></pre>
<p>As it is very easy to forget to close the file, we should always use <code>with</code> statement. This also provides better syntax and exceptions handling.</p>
</div>
<div id="python-csv-library" class="section level4">
<h4>2. Python <code>csv</code> library</h4>
<p>The <code>sample.txt</code> we just processed had only one field per line, which make it handy to process using just build-in function (<code>read()</code>, <code>readline()</code>, and <code>readlines()</code>). However, more frequently we will work with a file that has multiple fields on each line (aka <strong>tabular data</strong>), as shown in Figure 4. <img src="Figure4.png" alt="Figure 4" /></p>
<p>As we can see that every filed on each line is comma-separated, indicating where one field ends and the next field starts. We call this type of file the <strong>delimited file</strong>. These files are often either comma-separated (<code>.csv</code>)or tab-separated (<code>.tsv</code> or <code>.txt</code>). In rare cases, you may also encounter other delimiters like colon (<code>:</code>), semi-colon (<code>;</code>), and characters.</p>
<p>Even though the build-in function can still process these files, it is highly likely to mess up, especially when there are hundreds of fileds per line in some cases. Alternatively, we can use <a href="https://docs.python.org/3/library/csv.html">Python’s <code>csv</code> library</a> designed to read delimited files. Here let’s learn two common functions from this module.</p>
<ul>
<li><p><code>csv.reader()</code>: this reads all lines in the given file and returns a reader object. Then each line can be returned as a list of strings. <img src="Figure5.png" alt="Figure 5" /></p></li>
<li><p><code>csv.DictReader()</code>: if the file has headers (normally the first row that identifies each filed of data), this function reads each line as a dict with the headers as <code>keys</code> (Figure 6, upper panel). We then can access data of each column by calling its fieldname (Figure 6, lower panel) <img src="Figure6.png" alt="Figure 6" /></p></li>
</ul>
</div>
<div id="import-data-using-pandas" class="section level4">
<h4>3. Import data using Pandas</h4>
<p>Another very popular option in importing data in Python must go to <a href="https://pandas.pydata.org/getting_started.html"><strong>Pandas</strong></a>, especially when the data size is big (like several hundred MBs). We won’t delve into the specifics of how <code>pandas</code> works or how to use it. There are many excellent <a href="https://www.datacamp.com/community/tutorials/pandas-read-csv">tutorials</a> and books (e.g. <a href="https://www.amazon.com/gp/product/1491957662/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=quantpytho-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1491957662&amp;linkId=ea8de4253cce96046e8ab0383ac71b33">Python for Data Analysis</a>, by <a href="https://wesmckinney.com/">Wes McKinney</a>, creator of pandas). Here we just show some of the power of <code>pandas</code> in reading <code>csv</code> and <code>excel</code> files.</p>
<ul>
<li><p><code>pd.read_csv()</code>: this reads a <code>csv</code> file into <code>DataFrame</code> object. An important point here is that <code>pandas</code> is smart enough to automatically tell the header row and data type of each field, which make the downstream analyse more efficient. <img src="Figure7.png" alt="Figure 7" /></p></li>
<li><p><code>pd.read_excel(</code>): this reads an excel file (<code>.xls</code>, <code>.xlsx</code>, <code>.xlsm</code>, <code>.xlsb</code>, and <code>.odf</code> file extensions) into a pandas <code>DataFrame</code>. By default, it only import the first data sheet within the excel file (<code>sample.xlsx</code> has multiple sheets), as shown in Figure 8. <img src="Figure8.png" alt="Figure 8" /></p></li>
</ul>
<p>To be able to access a specific sheet within the excel file, we can first import the whole excel file using <code>pd.ExcelFile()</code> and then specify the sheet name when calling <code>pd.read_excel()</code> (Figure 8).</p>
<p>Moreover, to be handier in accessing all sheets, instead of calling <code>pd.read_excel()</code> multiple times, we can store all sheets as <code>dataframe</code> objects inside a <code>dict</code> (Figure 9). A practical example can also be found in this <a href="https://towardsdatascience.com/build-a-dashboard-to-track-the-spread-of-coronavirus-using-dash-90364f016764">post</a>. <img src="Figure9.png" alt="Figure 9" /></p>
</div>
<div id="options-for-importing-large-size-data" class="section level4">
<h4>4. Options for importing large size data</h4>
<p>In the age of big data, sometimes, we need to import files from a client or colleague, which may be too large (gigabytes or terabytes) to load into memory. So what should we do to tackle this bottleneck?</p>
<p>Fortunately, Pandas provides <code>chunksize</code> option to work this around. Essentially, we are not importing the whole file in one go instead of importing partial contents.</p>
<p>In addition, I found a very useful <a href="https://medium.com/casual-inference/the-most-time-efficient-ways-to-import-csv-data-in-python-cc159b44063d">post</a> by Mihail Yanchev, where he provided multiple methods and compared their efficiency in handling this situation. Here I just list those methods mentioned in his post and you can read his post if that is what you are looking for.</p>
<ul>
<li><p><a href="https://docs.dask.org/en/latest/dataframe.html">dask.dataframe()</a>: a large parallel DataFrame composed of many smaller Pandas DataFrames, split along the index. A good thing is that most functions used with pandas can also be used with dask.</p></li>
<li><p><a href="https://github.com/h2oai/datatable">datatable</a>: a Python package for manipulating big 2-dimensional tabular data structures (aka data frames, up to 100GB).</p></li>
</ul>
<hr />
<p>Alright, now we know the basics of importing data in Python. Of course, there are many other cases in importing data in Python that I cannot list them all here, like parsing <code>html</code> using <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> and reading sql table using <code>pd.read_sql_query()</code>. I hope this post gets you to start from the ground and up to explore more possibilities.</p>
<p>Here are links you may be interested in:</p>
<ul>
<li><a href="https://www.datacamp.com/community/blog/importing-data-python-cheat-sheet">Importing data in Python cheat sheet</a></li>
<li><a href="https://realpython.com/read-write-files-python/">Reading and Writing Files in Python (Guide)</a></li>
<li><a href="https://realpython.com/python-csv/">Reading and Writing csv file in Python</a></li>
<li><a href="https://realpython.com/python-json/">Reading and Writing json data in Python</a></li>
<li><a href="http://acepor.github.io/2017/08/03/using-chunksize/">Using chunksize in Pandas</a></li>
<li><a href="https://www.listendata.com/2017/02/import-data-in-python.html">How to import various data using Pandas</a></li>
<li><a href="https://towardsdatascience.com/an-overview-of-pythons-datatable-package-5d3a97394ee9">An Overview of Python’s Datatable package</a></li>
</ul>
<hr />
<p>As always, I welcome feedback, constructive criticism, and hearing about your data science projects. I can be reached on <a href="https://www.linkedin.com/in/jun-ye-29aaa769/">Linkedin</a>, and now on my <a href="https://junye0798.com/">website</a> as well.</p>
</div>
